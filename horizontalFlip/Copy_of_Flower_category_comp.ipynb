{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Copy of Flower category comp.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sagar9926/FlowerClassification/blob/master/horizontalFlip/Copy_of_Flower_category_comp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UP7o5b3eag6",
        "colab_type": "code",
        "outputId": "e7d0a7b2-281e-46ad-8a8e-7562bf5a88e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# Colab library to upload files to notebook\n",
        "#from google.colab import files\n",
        "\n",
        "# Install Kaggle library\n",
        "!pip install  kaggle\n",
        "\n",
        "from keras import regularizers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "#print(os.listdir(\"../input/flower-recognition-he/data\"))\n",
        "from tqdm import tqdm\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D,AveragePooling2D\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Activation, Flatten, Dense, Dropout\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.5)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.6.16)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n",
            "Requirement already satisfied: text-unidecode==1.2 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.2)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcFbtdjFT0UY",
        "colab_type": "code",
        "outputId": "0784c5f0-4093-46c2-8ff6-ef472c2ce055",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd .."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VbAEqKqT2G3",
        "colab_type": "code",
        "outputId": "6b9e3d96-dcfd-47bd-cc61-bd438ea273d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd content"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKwnt6beS8Lc",
        "colab_type": "code",
        "outputId": "5f869555-4cea-4886-f4ea-6203f1f83fe8",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "# Run this cell and select the kaggle.json file downloaded\n",
        "# from the Kaggle account settings page.\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-33b2dec7-e463-4575-8974-026d74b966a3\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-33b2dec7-e463-4575-8974-026d74b966a3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle (1).json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"agrawalsagar178\",\"key\":\"3e3a262202b2c8a388745d9de04e10af\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UB9AjnrUBjF",
        "colab_type": "code",
        "outputId": "f7b6623b-2634-4f93-a85b-12414814deba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " data\t\t\t    'kaggle (1).json'   sample_data\n",
            " flower-recognition-he.zip   kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pudy_hW-TMQy",
        "colab_type": "code",
        "outputId": "3a610a98-bf00-48d2-bd2d-0cb89c78ac0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Let's make sure the kaggle.json file is present.\n",
        "!ls -lha kaggle.json"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 71 Aug 10 14:12 kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5FFWmIKUwSY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Next, install the Kaggle API client.\n",
        "!pip install -q kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXMGUDxPU0V7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The Kaggle API client expects this file to be in ~/.kaggle,\n",
        "# so move it there.\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# This permissions change avoids a warning on Kaggle tool startup.\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAbehViqU3Ux",
        "colab_type": "code",
        "outputId": "80b205b8-1496-4dd0-d950-59829c09d06d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! kaggle datasets download -d rednivrug/flower-recognition-he -p /content\n",
        "\n",
        "#kaggle kernels pull rednivrug/flower-recogition-hackerearth-ensemble"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "flower-recognition-he.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9_FcpVEsnTd",
        "colab_type": "code",
        "outputId": "f4d3181b-29a3-4ee1-db8c-2df732d164bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Unzip the data\n",
        "!unzip flower-recognition-he.zip"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  flower-recognition-he.zip\n",
            "replace data/sample_submission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNLQOvsfsw3j",
        "colab_type": "code",
        "outputId": "749478fe-ca37-4d5f-f4f2-78781a417f19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Let's check the labels\n",
        "train_category = pd.read_csv(\"data/train.csv\")\n",
        "train_category.category.value_counts()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51     582\n",
              "77     567\n",
              "46     441\n",
              "73     438\n",
              "89     414\n",
              "74     387\n",
              "81     375\n",
              "94     366\n",
              "88     348\n",
              "78     309\n",
              "83     297\n",
              "43     294\n",
              "41     288\n",
              "95     288\n",
              "75     270\n",
              "58     258\n",
              "82     252\n",
              "60     246\n",
              "56     246\n",
              "76     243\n",
              "37     243\n",
              "80     237\n",
              "65     231\n",
              "72     216\n",
              "53     210\n",
              "44     210\n",
              "23     207\n",
              "96     207\n",
              "50     207\n",
              "12     198\n",
              "      ... \n",
              "64     117\n",
              "61     114\n",
              "19     111\n",
              "15     111\n",
              "49     111\n",
              "100    111\n",
              "13     111\n",
              "14     108\n",
              "102    108\n",
              "93     105\n",
              "9      105\n",
              "33     105\n",
              "32     102\n",
              "6      102\n",
              "10     102\n",
              "35      99\n",
              "67      96\n",
              "24      96\n",
              "39      93\n",
              "79      93\n",
              "25      93\n",
              "26      93\n",
              "16      93\n",
              "34      90\n",
              "3       90\n",
              "21      90\n",
              "7       90\n",
              "1       90\n",
              "27      90\n",
              "45      90\n",
              "Name: category, Length: 102, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3oxJ9iRvgXr",
        "colab_type": "code",
        "outputId": "e1a798f1-3f69-43ec-a0a4-d10f7f898644",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#%cd content\n",
        "%cd data\n",
        "!ls"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/data\n",
            "sample_submission.csv  test  test.csv  train  train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LCPJhWEqeQNe",
        "colab_type": "code",
        "outputId": "373dae17-be5e-497d-8dbc-073d5b33e9ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "\n",
        "img = image.load_img('../data/train/'+train_category['image_id'][0].astype('str')+'.jpg', target_size=(64,64,1))\n",
        "imgplot = plt.imshow(img)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "EwpROhi-eQNk",
        "colab_type": "code",
        "outputId": "c3a6324c-2469-464e-d1c3-9ee383cd1fed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Next, we will read all the training images, store them in a list, \n",
        "#and finally convert #that list into a numpy array.\n",
        "\n",
        "train_image = []\n",
        "for i in tqdm(range(train_category.shape[0])):\n",
        "    img = image.load_img('../data/train/'+train_category['image_id'][i].astype('str')+'.jpg', target_size=(64,64,1))\n",
        "    img = image.img_to_array(img)\n",
        "    img = img/255\n",
        "    train_image.append(img)\n",
        "X = np.array(train_image)\n",
        "\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|| 18540/18540 [01:22<00:00, 223.82it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qP4aHsfTCEMZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "L  = list(train_category.category)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9NboQ5ewVeU",
        "colab_type": "code",
        "outputId": "d4a98d4c-cb9e-45a5-fe88-f9a800c36b26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        }
      },
      "source": [
        "X[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.21176471, 0.25882354, 0.16470589],\n",
              "        [0.21568628, 0.24313726, 0.17254902],\n",
              "        [0.14509805, 0.19607843, 0.1254902 ],\n",
              "        ...,\n",
              "        [0.11372549, 0.17254902, 0.09019608],\n",
              "        [0.14509805, 0.21960784, 0.13333334],\n",
              "        [0.13333334, 0.20784314, 0.12156863]],\n",
              "\n",
              "       [[0.17254902, 0.24705882, 0.16078432],\n",
              "        [0.13725491, 0.21176471, 0.13725491],\n",
              "        [0.09019608, 0.14901961, 0.07450981],\n",
              "        ...,\n",
              "        [0.11764706, 0.16470589, 0.08627451],\n",
              "        [0.14117648, 0.21568628, 0.12941177],\n",
              "        [0.11372549, 0.1882353 , 0.10196079]],\n",
              "\n",
              "       [[0.20784314, 0.26666668, 0.14509805],\n",
              "        [0.11764706, 0.18039216, 0.07843138],\n",
              "        [0.07058824, 0.07450981, 0.04313726],\n",
              "        ...,\n",
              "        [0.07450981, 0.14117648, 0.06666667],\n",
              "        [0.10588235, 0.18039216, 0.09411765],\n",
              "        [0.1764706 , 0.27058825, 0.1764706 ]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0.05882353, 0.06666667, 0.04705882],\n",
              "        [0.05490196, 0.0627451 , 0.04313726],\n",
              "        [0.07058824, 0.07843138, 0.05882353],\n",
              "        ...,\n",
              "        [0.07843138, 0.15686275, 0.05098039],\n",
              "        [0.23529412, 0.28627452, 0.16862746],\n",
              "        [0.10588235, 0.1882353 , 0.12941177]],\n",
              "\n",
              "       [[0.03137255, 0.02352941, 0.02745098],\n",
              "        [0.02745098, 0.04705882, 0.01960784],\n",
              "        [0.06666667, 0.09803922, 0.03921569],\n",
              "        ...,\n",
              "        [0.0627451 , 0.12156863, 0.03137255],\n",
              "        [0.07058824, 0.14509805, 0.03529412],\n",
              "        [0.19607843, 0.23529412, 0.13725491]],\n",
              "\n",
              "       [[0.04705882, 0.03921569, 0.04313726],\n",
              "        [0.07843138, 0.09803922, 0.07058824],\n",
              "        [0.04313726, 0.09411765, 0.02745098],\n",
              "        ...,\n",
              "        [0.04705882, 0.10588235, 0.01568628],\n",
              "        [0.06666667, 0.12156863, 0.03137255],\n",
              "        [0.05882353, 0.12941177, 0.03529412]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "xO5LP5ZseQNq",
        "colab_type": "code",
        "outputId": "cf666eed-d451-45cb-c37e-f75093a70101",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18540, 64, 64, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "V1KWKQMleQNx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y=train_category['category'].values\n",
        "y = to_categorical(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "AwbniqcZeQN3",
        "colab_type": "code",
        "outputId": "bba076c9-c4c6-4736-eac2-da510e8f7ccd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(y[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "103"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8Z5WlQF9eQOC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.25,stratify = L )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KphD8zS3CL3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(featurewise_center=True, samplewise_center=True,horizontal_flip = True,vertical_flip = True)\n",
        "datagen.fit(X_train)\n",
        "\n",
        "val_datagen = ImageDataGenerator(featurewise_center=True, samplewise_center=True)\n",
        "val_datagen.fit(X_train)\n",
        "\n",
        "\n",
        "# demonstrate effect on entire training dataset\n",
        "train_iterator = datagen.flow(X_train, y_train, batch_size=128, shuffle=False) #what is the use of shuffle\n",
        "val_iterator = val_datagen.flow(X_test, y_test, batch_size=64, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AN9erOfKw-0R",
        "colab_type": "code",
        "outputId": "0b7cbd4c-24d9-42ae-9cd3-a51859d9a975",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "#Test accuracy 67\n",
        "\n",
        "# Define the model\n",
        "model1 = Sequential()\n",
        "model1.add(Convolution2D(32, 3, 3, border_mode='same',kernel_regularizer=regularizers.l2(0.0001), input_shape=(64, 64, 3)))\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.05))\n",
        "\n",
        "model1.add(Convolution2D(32, 3, 3, border_mode='same',kernel_regularizer=regularizers.l2(0.0001), input_shape=(64, 64, 3)))\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.05))\n",
        "\n",
        "model1.add(Convolution2D(64, 3, 3,kernel_regularizer=regularizers.l2(0.0001),border_mode='same'))\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.05))\n",
        "\n",
        "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model1.add(Dropout(0.25))\n",
        "\n",
        "model1.add(Convolution2D(32, 1, 1))\n",
        "\n",
        "\n",
        "model1.add(Convolution2D(64, 3, 3,kernel_regularizer=regularizers.l2(0.0001),border_mode='same'))\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.05))\n",
        "\n",
        "model1.add(Convolution2D(64, 3, 3,kernel_regularizer=regularizers.l2(0.0001),border_mode='same'))\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.05))\n",
        "\n",
        "model1.add(Convolution2D(128, 3, 3,kernel_regularizer=regularizers.l2(0.0001),border_mode='same'))\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.05))\n",
        "\n",
        "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model1.add(Dropout(0.35))\n",
        "\n",
        "model1.add(Convolution2D(32, 1, 1))\n",
        "\n",
        "\n",
        "model1.add(Convolution2D(128, 3, 3,kernel_regularizer=regularizers.l2(0.0001), border_mode='same'))\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.05))\n",
        "\n",
        "model1.add(Convolution2D(128, 3, 3,kernel_regularizer=regularizers.l2(0.0001), border_mode='same'))\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.05))\n",
        "\n",
        "model1.add(Convolution2D(256, 3, 3,kernel_regularizer=regularizers.l2(0.0001), border_mode='same'))\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.05))\n",
        "\n",
        "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model1.add(Dropout(0.5))\n",
        "\n",
        "model1.add(Convolution2D(103, 2, 2))\n",
        "\n",
        "model1.add(AveragePooling2D(pool_size = (4,4)))\n",
        "model1.add(Flatten())\n",
        "\n",
        "\n",
        "model1.add(Activation('softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), kernel_regularizer=<keras.reg..., input_shape=(64, 64, 3..., padding=\"same\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), kernel_regularizer=<keras.reg..., input_shape=(64, 64, 3..., padding=\"same\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), kernel_regularizer=<keras.reg..., padding=\"same\")`\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (1, 1))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), kernel_regularizer=<keras.reg..., padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), kernel_regularizer=<keras.reg..., padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), kernel_regularizer=<keras.reg..., padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (1, 1))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:44: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), kernel_regularizer=<keras.reg..., padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), kernel_regularizer=<keras.reg..., padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), kernel_regularizer=<keras.reg..., padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:62: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(103, (2, 2))`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5bHD3jC2a1V",
        "colab_type": "code",
        "outputId": "d84c1613-6757-4886-8efe-ec4bfb2d0fc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model1.summary()"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_73 (Conv2D)           (None, 64, 64, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_61 (Activation)   (None, 64, 64, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_55 (Batc (None, 64, 64, 32)        128       \n",
            "_________________________________________________________________\n",
            "dropout_55 (Dropout)         (None, 64, 64, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_74 (Conv2D)           (None, 64, 64, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_62 (Activation)   (None, 64, 64, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_56 (Batc (None, 64, 64, 32)        128       \n",
            "_________________________________________________________________\n",
            "dropout_56 (Dropout)         (None, 64, 64, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_75 (Conv2D)           (None, 64, 64, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_63 (Activation)   (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_57 (Batc (None, 64, 64, 64)        256       \n",
            "_________________________________________________________________\n",
            "dropout_57 (Dropout)         (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_58 (Dropout)         (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_76 (Conv2D)           (None, 32, 32, 32)        2080      \n",
            "_________________________________________________________________\n",
            "conv2d_77 (Conv2D)           (None, 32, 32, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_64 (Activation)   (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_58 (Batc (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "dropout_59 (Dropout)         (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_78 (Conv2D)           (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_65 (Activation)   (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_59 (Batc (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "dropout_60 (Dropout)         (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_79 (Conv2D)           (None, 32, 32, 128)       73856     \n",
            "_________________________________________________________________\n",
            "activation_66 (Activation)   (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_60 (Batc (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "dropout_61 (Dropout)         (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_62 (Dropout)         (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_80 (Conv2D)           (None, 16, 16, 32)        4128      \n",
            "_________________________________________________________________\n",
            "conv2d_81 (Conv2D)           (None, 16, 16, 128)       36992     \n",
            "_________________________________________________________________\n",
            "activation_67 (Activation)   (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_61 (Batc (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "dropout_63 (Dropout)         (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_82 (Conv2D)           (None, 16, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "activation_68 (Activation)   (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_62 (Batc (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "dropout_64 (Dropout)         (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_83 (Conv2D)           (None, 16, 16, 256)       295168    \n",
            "_________________________________________________________________\n",
            "activation_69 (Activation)   (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_63 (Batc (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "dropout_65 (Dropout)         (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_21 (MaxPooling (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_66 (Dropout)         (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_84 (Conv2D)           (None, 7, 7, 103)         105575    \n",
            "_________________________________________________________________\n",
            "average_pooling2d_7 (Average (None, 1, 1, 103)         0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 103)               0         \n",
            "_________________________________________________________________\n",
            "activation_70 (Activation)   (None, 103)               0         \n",
            "=================================================================\n",
            "Total params: 753,031\n",
            "Trainable params: 751,239\n",
            "Non-trainable params: 1,792\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SX1IVwxoOKFo",
        "colab_type": "code",
        "outputId": "a6aa4e9e-61a5-4e10-b152-fc2ea52e808d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4635, 64, 64, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDj0lD9WEKCE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(featurewise_center=True, samplewise_center=True,vertical_flip = True,preprocessing_function=get_random_eraser(v_l=0, v_h=1),rotation_range=10,width_shift_range=0.2,\n",
        "    height_shift_range=0.2)\n",
        "datagen.fit(X_train)\n",
        "\n",
        "val_datagen = ImageDataGenerator(featurewise_center=True, samplewise_center=True)\n",
        "val_datagen.fit(X_train)\n",
        "\n",
        "\n",
        "# demonstrate effect on entire training dataset\n",
        "train_iterator = datagen.flow(X_train, y_train, batch_size=256, shuffle=False) #what is the use of shuffle\n",
        "val_iterator = val_datagen.flow(X_test, y_test, batch_size=64, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5SXEYRBWzpb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "17b67548-172c-4927-947a-e0d76944cb36"
      },
      "source": [
        "!git clone https://github.com/bckenstler/CLR.git"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CLR'...\n",
            "remote: Enumerating objects: 244, done.\u001b[K\n",
            "remote: Total 244 (delta 0), reused 0 (delta 0), pack-reused 244\u001b[K\n",
            "Receiving objects: 100% (244/244), 1.37 MiB | 2.89 MiB/s, done.\n",
            "Resolving deltas: 100% (86/86), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1EsmnqmXG7W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "169ce36b-077a-45b8-f862-4526e64e0373"
      },
      "source": [
        "cd test"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/data/test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nF5n1Gthc9HB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import *\n",
        "from clr_callback import *\n",
        "from keras.optimizers import SGD\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQKE0PeMdSCv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# You are using the triangular learning rate policy and\n",
        "#  base_lr (initial learning rate which is the lower boundary in the cycle) is 0.1\n",
        "clr_triangular = CyclicLR(mode='triangular')\n",
        "model1.compile(optimizer=SGD(0.01), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQ3yTcJjdQQR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " mcp_save = ModelCheckpoint('../data/mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60GPxw1NY77o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a5deab55-e73d-4292-a344-fbf24180a163"
      },
      "source": [
        "cd .."
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "52K6NkjIeQOM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktZ1ncbMR54U",
        "colab_type": "code",
        "outputId": "f6e1e6d8-0db6-4ca0-eb3f-aa8f408b13d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#103\n",
        "model1.fit_generator(train_iterator, steps_per_epoch=55, verbose=1,nb_epoch=200,\n",
        "                    validation_data=val_iterator,validation_steps = 71,callbacks=[mcp_save,clr_triangular] )"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., steps_per_epoch=55, verbose=1, validation_data=<keras_pre..., validation_steps=71, callbacks=[<keras.ca..., epochs=200)`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "55/55 [==============================] - 44s 802ms/step - loss: 3.9492 - acc: 0.1193 - val_loss: 4.7429 - val_acc: 0.1591\n",
            "Epoch 2/200\n",
            "55/55 [==============================] - 38s 696ms/step - loss: 3.1236 - acc: 0.2380 - val_loss: 3.8586 - val_acc: 0.2276\n",
            "Epoch 3/200\n",
            "55/55 [==============================] - 38s 693ms/step - loss: 2.7710 - acc: 0.2983 - val_loss: 3.9941 - val_acc: 0.2665\n",
            "Epoch 4/200\n",
            "55/55 [==============================] - 38s 693ms/step - loss: 2.5582 - acc: 0.3440 - val_loss: 4.5074 - val_acc: 0.2248\n",
            "Epoch 5/200\n",
            "55/55 [==============================] - 38s 694ms/step - loss: 2.3984 - acc: 0.3794 - val_loss: 6.6239 - val_acc: 0.1722\n",
            "Epoch 6/200\n",
            "55/55 [==============================] - 38s 694ms/step - loss: 2.2177 - acc: 0.4236 - val_loss: 4.4609 - val_acc: 0.2518\n",
            "Epoch 7/200\n",
            "55/55 [==============================] - 38s 693ms/step - loss: 2.0960 - acc: 0.4504 - val_loss: 3.7436 - val_acc: 0.3046\n",
            "Epoch 8/200\n",
            "55/55 [==============================] - 38s 691ms/step - loss: 1.9758 - acc: 0.4825 - val_loss: 4.2631 - val_acc: 0.2842\n",
            "Epoch 9/200\n",
            "55/55 [==============================] - 38s 692ms/step - loss: 1.8673 - acc: 0.5153 - val_loss: 5.6222 - val_acc: 0.2190\n",
            "Epoch 10/200\n",
            "55/55 [==============================] - 38s 690ms/step - loss: 1.7526 - acc: 0.5430 - val_loss: 4.5488 - val_acc: 0.2807\n",
            "Epoch 11/200\n",
            "55/55 [==============================] - 38s 690ms/step - loss: 1.6849 - acc: 0.5604 - val_loss: 5.1308 - val_acc: 0.2702\n",
            "Epoch 12/200\n",
            "55/55 [==============================] - 38s 690ms/step - loss: 1.6725 - acc: 0.5672 - val_loss: 6.0833 - val_acc: 0.2423\n",
            "Epoch 13/200\n",
            "55/55 [==============================] - 38s 690ms/step - loss: 1.5604 - acc: 0.5993 - val_loss: 5.4801 - val_acc: 0.3071\n",
            "Epoch 14/200\n",
            "55/55 [==============================] - 38s 690ms/step - loss: 1.5493 - acc: 0.6020 - val_loss: 7.1147 - val_acc: 0.2474\n",
            "Epoch 15/200\n",
            "55/55 [==============================] - 38s 690ms/step - loss: 1.4955 - acc: 0.6177 - val_loss: 6.5186 - val_acc: 0.2829\n",
            "Epoch 16/200\n",
            "55/55 [==============================] - 38s 690ms/step - loss: 1.5119 - acc: 0.6222 - val_loss: 4.8566 - val_acc: 0.3628\n",
            "Epoch 17/200\n",
            "55/55 [==============================] - 38s 691ms/step - loss: 1.4459 - acc: 0.6398 - val_loss: 5.0958 - val_acc: 0.3583\n",
            "Epoch 18/200\n",
            "55/55 [==============================] - 38s 690ms/step - loss: 1.4199 - acc: 0.6514 - val_loss: 4.3550 - val_acc: 0.4149\n",
            "Epoch 19/200\n",
            "55/55 [==============================] - 38s 689ms/step - loss: 1.3754 - acc: 0.6605 - val_loss: 4.4611 - val_acc: 0.4065\n",
            "Epoch 20/200\n",
            "55/55 [==============================] - 38s 689ms/step - loss: 1.3293 - acc: 0.6793 - val_loss: 4.4637 - val_acc: 0.4032\n",
            "Epoch 21/200\n",
            "55/55 [==============================] - 38s 686ms/step - loss: 1.3348 - acc: 0.6760 - val_loss: 3.8924 - val_acc: 0.4358\n",
            "Epoch 22/200\n",
            "55/55 [==============================] - 38s 690ms/step - loss: 1.3436 - acc: 0.6782 - val_loss: 3.8113 - val_acc: 0.4875\n",
            "Epoch 23/200\n",
            "55/55 [==============================] - 38s 689ms/step - loss: 1.3183 - acc: 0.6949 - val_loss: 4.8032 - val_acc: 0.4063\n",
            "Epoch 24/200\n",
            "55/55 [==============================] - 38s 687ms/step - loss: 1.3032 - acc: 0.6981 - val_loss: 4.0100 - val_acc: 0.4471\n",
            "Epoch 25/200\n",
            "55/55 [==============================] - 38s 687ms/step - loss: 1.2974 - acc: 0.6998 - val_loss: 4.1873 - val_acc: 0.4624\n",
            "Epoch 26/200\n",
            "55/55 [==============================] - 38s 688ms/step - loss: 1.2934 - acc: 0.7072 - val_loss: 4.2149 - val_acc: 0.4438\n",
            "Epoch 27/200\n",
            "55/55 [==============================] - 38s 689ms/step - loss: 1.2896 - acc: 0.7141 - val_loss: 3.7394 - val_acc: 0.4684\n",
            "Epoch 28/200\n",
            "55/55 [==============================] - 38s 688ms/step - loss: 1.2801 - acc: 0.7194 - val_loss: 2.8314 - val_acc: 0.5729\n",
            "Epoch 29/200\n",
            "55/55 [==============================] - 38s 689ms/step - loss: 1.2774 - acc: 0.7213 - val_loss: 2.8345 - val_acc: 0.5516\n",
            "Epoch 30/200\n",
            "55/55 [==============================] - 38s 687ms/step - loss: 1.2655 - acc: 0.7294 - val_loss: 4.6361 - val_acc: 0.4533\n",
            "Epoch 31/200\n",
            "55/55 [==============================] - 38s 686ms/step - loss: 1.2828 - acc: 0.7289 - val_loss: 3.1931 - val_acc: 0.5671\n",
            "Epoch 32/200\n",
            "55/55 [==============================] - 38s 689ms/step - loss: 1.2679 - acc: 0.7333 - val_loss: 4.1107 - val_acc: 0.4595\n",
            "Epoch 33/200\n",
            "55/55 [==============================] - 38s 688ms/step - loss: 1.2617 - acc: 0.7365 - val_loss: 3.0325 - val_acc: 0.5755\n",
            "Epoch 34/200\n",
            "55/55 [==============================] - 38s 685ms/step - loss: 1.2858 - acc: 0.7364 - val_loss: 2.6696 - val_acc: 0.5698\n",
            "Epoch 35/200\n",
            "55/55 [==============================] - 38s 687ms/step - loss: 1.3166 - acc: 0.7301 - val_loss: 3.5844 - val_acc: 0.5057\n",
            "Epoch 36/200\n",
            "55/55 [==============================] - 38s 691ms/step - loss: 1.2858 - acc: 0.7400 - val_loss: 2.6528 - val_acc: 0.6082\n",
            "Epoch 37/200\n",
            "55/55 [==============================] - 38s 693ms/step - loss: 1.2830 - acc: 0.7485 - val_loss: 2.1336 - val_acc: 0.6582\n",
            "Epoch 38/200\n",
            "55/55 [==============================] - 38s 692ms/step - loss: 1.2759 - acc: 0.7498 - val_loss: 2.9013 - val_acc: 0.5818\n",
            "Epoch 39/200\n",
            "55/55 [==============================] - 38s 693ms/step - loss: 1.2481 - acc: 0.7590 - val_loss: 2.1096 - val_acc: 0.6470\n",
            "Epoch 40/200\n",
            "55/55 [==============================] - 38s 693ms/step - loss: 1.2109 - acc: 0.7698 - val_loss: 1.7815 - val_acc: 0.7320\n",
            "Epoch 41/200\n",
            "55/55 [==============================] - 38s 693ms/step - loss: 1.1992 - acc: 0.7763 - val_loss: 2.8194 - val_acc: 0.5960\n",
            "Epoch 42/200\n",
            "55/55 [==============================] - 38s 693ms/step - loss: 1.2246 - acc: 0.7704 - val_loss: 2.1483 - val_acc: 0.6532\n",
            "Epoch 43/200\n",
            "55/55 [==============================] - 38s 691ms/step - loss: 1.1864 - acc: 0.7824 - val_loss: 1.7726 - val_acc: 0.7089\n",
            "Epoch 44/200\n",
            "55/55 [==============================] - 38s 692ms/step - loss: 1.1293 - acc: 0.8001 - val_loss: 3.0621 - val_acc: 0.5381\n",
            "Epoch 45/200\n",
            "55/55 [==============================] - 38s 692ms/step - loss: 1.1246 - acc: 0.7978 - val_loss: 1.5771 - val_acc: 0.7291\n",
            "Epoch 46/200\n",
            "55/55 [==============================] - 38s 692ms/step - loss: 1.1281 - acc: 0.7993 - val_loss: 2.0650 - val_acc: 0.6747\n",
            "Epoch 47/200\n",
            "55/55 [==============================] - 38s 693ms/step - loss: 1.1376 - acc: 0.7940 - val_loss: 1.3884 - val_acc: 0.7659\n",
            "Epoch 48/200\n",
            "55/55 [==============================] - 38s 694ms/step - loss: 1.0769 - acc: 0.8160 - val_loss: 1.9202 - val_acc: 0.6967\n",
            "Epoch 49/200\n",
            "55/55 [==============================] - 38s 693ms/step - loss: 1.0568 - acc: 0.8159 - val_loss: 1.7290 - val_acc: 0.7220\n",
            "Epoch 50/200\n",
            "55/55 [==============================] - 38s 693ms/step - loss: 1.0877 - acc: 0.8089 - val_loss: 1.8213 - val_acc: 0.7025\n",
            "Epoch 51/200\n",
            "55/55 [==============================] - 38s 691ms/step - loss: 1.0709 - acc: 0.8134 - val_loss: 2.1061 - val_acc: 0.6505\n",
            "Epoch 52/200\n",
            "55/55 [==============================] - 38s 693ms/step - loss: 1.0288 - acc: 0.8253 - val_loss: 1.4294 - val_acc: 0.7542\n",
            "Epoch 53/200\n",
            "55/55 [==============================] - 38s 692ms/step - loss: 1.0071 - acc: 0.8294 - val_loss: 1.9093 - val_acc: 0.7065\n",
            "Epoch 54/200\n",
            "55/55 [==============================] - 38s 694ms/step - loss: 0.9891 - acc: 0.8315 - val_loss: 1.4533 - val_acc: 0.7659\n",
            "Epoch 55/200\n",
            "55/55 [==============================] - 38s 691ms/step - loss: 0.9829 - acc: 0.8332 - val_loss: 1.5591 - val_acc: 0.7415\n",
            "Epoch 56/200\n",
            "55/55 [==============================] - 38s 693ms/step - loss: 0.9656 - acc: 0.8393 - val_loss: 1.4286 - val_acc: 0.7633\n",
            "Epoch 57/200\n",
            "55/55 [==============================] - 38s 693ms/step - loss: 0.9292 - acc: 0.8469 - val_loss: 1.6422 - val_acc: 0.7446\n",
            "Epoch 58/200\n",
            "55/55 [==============================] - 38s 693ms/step - loss: 0.8889 - acc: 0.8596 - val_loss: 1.0813 - val_acc: 0.8252\n",
            "Epoch 59/200\n",
            "55/55 [==============================] - 38s 692ms/step - loss: 0.8882 - acc: 0.8526 - val_loss: 2.0921 - val_acc: 0.6734\n",
            "Epoch 60/200\n",
            "55/55 [==============================] - 38s 692ms/step - loss: 0.9083 - acc: 0.8515 - val_loss: 1.0364 - val_acc: 0.8276\n",
            "Epoch 61/200\n",
            "55/55 [==============================] - 38s 691ms/step - loss: 0.8554 - acc: 0.8637 - val_loss: 1.4487 - val_acc: 0.7657\n",
            "Epoch 62/200\n",
            "55/55 [==============================] - 38s 691ms/step - loss: 0.8425 - acc: 0.8650 - val_loss: 1.3703 - val_acc: 0.7957\n",
            "Epoch 63/200\n",
            "55/55 [==============================] - 38s 691ms/step - loss: 0.8448 - acc: 0.8632 - val_loss: 1.4617 - val_acc: 0.7615\n",
            "Epoch 64/200\n",
            "55/55 [==============================] - 38s 693ms/step - loss: 0.8131 - acc: 0.8747 - val_loss: 1.1814 - val_acc: 0.8158\n",
            "Epoch 65/200\n",
            "55/55 [==============================] - 38s 693ms/step - loss: 0.7985 - acc: 0.8747 - val_loss: 1.3051 - val_acc: 0.7903\n",
            "Epoch 66/200\n",
            "55/55 [==============================] - 38s 693ms/step - loss: 0.7720 - acc: 0.8794 - val_loss: 1.0748 - val_acc: 0.8354\n",
            "Epoch 67/200\n",
            "55/55 [==============================] - 38s 692ms/step - loss: 0.7442 - acc: 0.8871 - val_loss: 1.0923 - val_acc: 0.8181\n",
            "Epoch 68/200\n",
            "55/55 [==============================] - 38s 694ms/step - loss: 0.7144 - acc: 0.8940 - val_loss: 1.2730 - val_acc: 0.7748\n",
            "Epoch 69/200\n",
            "55/55 [==============================] - 38s 693ms/step - loss: 0.7000 - acc: 0.8978 - val_loss: 1.4359 - val_acc: 0.7777\n",
            "Epoch 70/200\n",
            "55/55 [==============================] - 38s 692ms/step - loss: 0.6710 - acc: 0.9046 - val_loss: 0.9590 - val_acc: 0.8520\n",
            "Epoch 71/200\n",
            "55/55 [==============================] - 38s 692ms/step - loss: 0.6624 - acc: 0.9067 - val_loss: 0.9535 - val_acc: 0.8505\n",
            "Epoch 72/200\n",
            "55/55 [==============================] - 38s 693ms/step - loss: 0.6317 - acc: 0.9121 - val_loss: 0.9827 - val_acc: 0.8449\n",
            "Epoch 73/200\n",
            "55/55 [==============================] - 38s 693ms/step - loss: 0.6107 - acc: 0.9188 - val_loss: 1.0505 - val_acc: 0.8309\n",
            "Epoch 74/200\n",
            "55/55 [==============================] - 38s 693ms/step - loss: 0.6183 - acc: 0.9135 - val_loss: 0.8720 - val_acc: 0.8666\n",
            "Epoch 75/200\n",
            "55/55 [==============================] - 38s 692ms/step - loss: 0.6256 - acc: 0.9111 - val_loss: 1.0175 - val_acc: 0.8460\n",
            "Epoch 76/200\n",
            "55/55 [==============================] - 38s 693ms/step - loss: 0.6248 - acc: 0.9054 - val_loss: 0.9685 - val_acc: 0.8422\n",
            "Epoch 77/200\n",
            "55/55 [==============================] - 38s 693ms/step - loss: 0.6346 - acc: 0.9045 - val_loss: 1.2106 - val_acc: 0.8096\n",
            "Epoch 78/200\n",
            "55/55 [==============================] - 38s 692ms/step - loss: 0.6700 - acc: 0.8937 - val_loss: 1.1524 - val_acc: 0.8141\n",
            "Epoch 79/200\n",
            "55/55 [==============================] - 38s 692ms/step - loss: 0.6812 - acc: 0.8887 - val_loss: 1.0127 - val_acc: 0.8485\n",
            "Epoch 80/200\n",
            "55/55 [==============================] - 38s 693ms/step - loss: 0.7111 - acc: 0.8825 - val_loss: 1.4446 - val_acc: 0.7708\n",
            "Epoch 81/200\n",
            "55/55 [==============================] - 38s 693ms/step - loss: 0.7577 - acc: 0.8715 - val_loss: 1.4705 - val_acc: 0.7779\n",
            "Epoch 82/200\n",
            "55/55 [==============================] - 38s 691ms/step - loss: 0.8016 - acc: 0.8549 - val_loss: 1.2517 - val_acc: 0.7981\n",
            "Epoch 83/200\n",
            "55/55 [==============================] - 38s 691ms/step - loss: 0.7990 - acc: 0.8653 - val_loss: 1.9269 - val_acc: 0.7479\n",
            "Epoch 84/200\n",
            "55/55 [==============================] - 38s 690ms/step - loss: 0.8441 - acc: 0.8503 - val_loss: 2.4644 - val_acc: 0.6763\n",
            "Epoch 85/200\n",
            "55/55 [==============================] - 38s 690ms/step - loss: 0.8932 - acc: 0.8417 - val_loss: 1.6249 - val_acc: 0.7444\n",
            "Epoch 86/200\n",
            "55/55 [==============================] - 38s 691ms/step - loss: 0.9052 - acc: 0.8387 - val_loss: 1.7515 - val_acc: 0.7488\n",
            "Epoch 87/200\n",
            "55/55 [==============================] - 38s 691ms/step - loss: 0.9422 - acc: 0.8321 - val_loss: 1.8259 - val_acc: 0.7266\n",
            "Epoch 88/200\n",
            "55/55 [==============================] - 38s 690ms/step - loss: 0.9292 - acc: 0.8377 - val_loss: 2.0510 - val_acc: 0.7078\n",
            "Epoch 89/200\n",
            "55/55 [==============================] - 38s 692ms/step - loss: 0.9543 - acc: 0.8366 - val_loss: 2.0301 - val_acc: 0.7255\n",
            "Epoch 90/200\n",
            "55/55 [==============================] - 38s 690ms/step - loss: 0.9526 - acc: 0.8389 - val_loss: 2.2082 - val_acc: 0.6769\n",
            "Epoch 91/200\n",
            "55/55 [==============================] - 38s 690ms/step - loss: 0.9989 - acc: 0.8257 - val_loss: 2.3832 - val_acc: 0.6652\n",
            "Epoch 92/200\n",
            "55/55 [==============================] - 38s 689ms/step - loss: 1.0273 - acc: 0.8202 - val_loss: 2.5331 - val_acc: 0.6583\n",
            "Epoch 93/200\n",
            "55/55 [==============================] - 38s 690ms/step - loss: 0.9916 - acc: 0.8339 - val_loss: 1.6967 - val_acc: 0.7497\n",
            "Epoch 94/200\n",
            "55/55 [==============================] - 38s 691ms/step - loss: 1.0313 - acc: 0.8247 - val_loss: 2.7981 - val_acc: 0.6153\n",
            "Epoch 95/200\n",
            "55/55 [==============================] - 38s 691ms/step - loss: 1.0550 - acc: 0.8194 - val_loss: 2.1791 - val_acc: 0.6909\n",
            "Epoch 96/200\n",
            "55/55 [==============================] - 38s 689ms/step - loss: 1.0801 - acc: 0.8150 - val_loss: 1.8508 - val_acc: 0.7349\n",
            "Epoch 97/200\n",
            "55/55 [==============================] - 38s 691ms/step - loss: 1.0504 - acc: 0.8273 - val_loss: 2.5021 - val_acc: 0.6292\n",
            "Epoch 98/200\n",
            "55/55 [==============================] - 38s 691ms/step - loss: 1.1143 - acc: 0.8115 - val_loss: 3.6065 - val_acc: 0.5403\n",
            "Epoch 99/200\n",
            "55/55 [==============================] - 38s 689ms/step - loss: 1.0910 - acc: 0.8200 - val_loss: 2.7795 - val_acc: 0.6381\n",
            "Epoch 100/200\n",
            "55/55 [==============================] - 38s 689ms/step - loss: 1.1186 - acc: 0.8129 - val_loss: 2.3258 - val_acc: 0.6634\n",
            "Epoch 101/200\n",
            "31/55 [===============>..............] - ETA: 15s - loss: 1.1677 - acc: 0.8062"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-154-a628f7d2c0a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model1.fit_generator(train_iterator, steps_per_epoch=55, verbose=1,nb_epoch=200,\n\u001b[0;32m----> 2\u001b[0;31m                     validation_data=val_iterator,validation_steps = 71,callbacks=[mcp_save,clr_triangular] )\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Qwo8lzzdpsN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1.load_weights(filepath = '../data/mdl_wts.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQB8OJ21NqJc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(featurewise_center=True, samplewise_center=True)\n",
        "datagen.fit(X_train)\n",
        "\n",
        "val_datagen = ImageDataGenerator(featurewise_center=True, samplewise_center=True)\n",
        "val_datagen.fit(X_train)\n",
        "\n",
        "\n",
        "# demonstrate effect on entire training dataset\n",
        "train_iterator = datagen.flow(X_train, y_train, batch_size=128, shuffle=False) #what is the use of shuffle\n",
        "val_iterator = val_datagen.flow(X_test, y_test, batch_size=64, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgozdRvisrZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfIBVY5UNySW",
        "colab_type": "code",
        "outputId": "fa646d28-7d21-4026-c948-28e65cd52218",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "#2 gave me 76.9\n",
        "#thus total 105 epochs\n",
        "model1.fit_generator(train_iterator, steps_per_epoch=109, verbose=1,nb_epoch=4,\n",
        "                    validation_data=val_iterator,validation_steps = 71)"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., steps_per_epoch=109, verbose=1, validation_data=<keras_pre..., validation_steps=71, epochs=4)`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "109/109 [==============================] - 40s 367ms/step - loss: 2.0438 - acc: 0.6297 - val_loss: 2.9711 - val_acc: 0.5775\n",
            "Epoch 2/4\n",
            "109/109 [==============================] - 40s 366ms/step - loss: 1.2380 - acc: 0.8149 - val_loss: 1.4724 - val_acc: 0.7506\n",
            "Epoch 3/4\n",
            "109/109 [==============================] - 40s 366ms/step - loss: 1.0174 - acc: 0.8685 - val_loss: 1.3901 - val_acc: 0.7686\n",
            "Epoch 4/4\n",
            "109/109 [==============================] - 40s 365ms/step - loss: 0.9331 - acc: 0.8867 - val_loss: 1.2800 - val_acc: 0.7872\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa5e7b4f278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUCZBEGsR6Le",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Implementing CutOut\n",
        "import cv2\n",
        "def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=False):\n",
        "    #cutout\n",
        "    def eraser(input_img):\n",
        "        img_h, img_w, img_c = input_img.shape\n",
        "        p_1 = np.random.rand()\n",
        "\n",
        "        if p_1 > p:\n",
        "            return input_img\n",
        "\n",
        "        while True:\n",
        "            s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
        "            r = np.random.uniform(r_1, r_2)\n",
        "            w = int(np.sqrt(s / r))\n",
        "            h = int(np.sqrt(s * r))\n",
        "            left = np.random.randint(0, img_w)\n",
        "            top = np.random.randint(0, img_h)\n",
        "\n",
        "            if left + w <= img_w and top + h <= img_h:\n",
        "                break\n",
        "\n",
        "        if pixel_level:\n",
        "            c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
        "        else:\n",
        "            c = np.random.uniform(v_l, v_h)\n",
        "\n",
        "        input_img[top:top + h, left:left + w, :] = c\n",
        "\n",
        "        return input_img\n",
        "    \n",
        "    #Random Crop\n",
        "    \n",
        "    def random_crop(input_img, random_crop_size =(64,64)):\n",
        "      # Note: image_data_format is 'channel_last'\n",
        "      assert input_img.shape[2] == 3\n",
        "      height, width = input_img.shape[0], input_img.shape[1]\n",
        "      dy, dx = random_crop_size\n",
        "      x = np.random.randint(0, width - dx + 1)\n",
        "      y = np.random.randint(0, height - dy + 1)\n",
        "      return input_img[y:(y+dy), x:(x+dx), :]\n",
        "    \n",
        "    \n",
        "    def Horizontal_Flip(input_img):\n",
        "      p0 = 0\n",
        "      \n",
        "      p_2 = np.random.rand()\n",
        "      \n",
        "      if p_2 > p0:\n",
        "        return input_img\n",
        "      else:\n",
        "        return(cv2.flip(input_img,1))\n",
        "      \n",
        "    #Adding padding\n",
        "    \n",
        "    def padding(input_image):\n",
        "      input_img = cv2.copyMakeBorder(input_image,0,4,4,0,cv2.BORDER_REPLICATE)\n",
        "      return input_img\n",
        "    \n",
        "    \n",
        "    def aggregate_all_augs(input_img):\n",
        "      return eraser(Horizontal_Flip(random_crop(padding(input_img))))\n",
        "\n",
        "    return aggregate_all_augs\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkLfnRsL9MDh",
        "colab_type": "text"
      },
      "source": [
        "#### Maximum accuracy achieved 85% in 17th epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "uFP2yAkieQOX",
        "colab_type": "code",
        "outputId": "7dcc6869-6cce-4f6f-c2f0-d1e37de6a39e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df_test = pd.read_csv(\"../data/test.csv\")\n",
        "df_test['image_id'][0]"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18540"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "KceJEKGXeQOb",
        "colab_type": "code",
        "outputId": "efe7e1ae-3aa3-4913-e51c-661816470c8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_image = []\n",
        "for i in tqdm(range(df_test.shape[0])):\n",
        "    img = image.load_img('../data/test/'+df_test['image_id'][i].astype('str')+'.jpg', target_size=(64,64,1))\n",
        "    img = image.img_to_array(img)\n",
        "    img = img/255\n",
        "    test_image.append(img)\n",
        "test = np.array(test_image)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|| 2009/2009 [00:09<00:00, 211.11it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhrSqMpeHuBF",
        "colab_type": "code",
        "outputId": "b1495a38-9f9d-4d79-9552-b6c88e0795f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test[1].max()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ZbW2WPmbeQOg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_datagen = ImageDataGenerator(featurewise_center=True, samplewise_center=True)\n",
        "test_datagen.fit(X_train)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test_iterator = test_datagen.flow(test, batch_size=49, shuffle=False)\n",
        "prediction = model1.predict_generator(test_iterator,steps =41)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IH97V7U0Uozb",
        "colab_type": "code",
        "outputId": "4c1e7183-6ba8-4633-f526-16002a53a227",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "prediction.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2009, 103)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lJv42DScPo9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict = [np.argmax(prediction[i]) for i in range(2009)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnQzxeuUmlAS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IcC_INxlT2J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "KynsnIlfeQOk",
        "colab_type": "code",
        "outputId": "38206fa1-2f32-400d-96f5-5cf7def3f398",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "df_prediction= pd.DataFrame({'category':predict})\n",
        "df_prediction"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1979</th>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1980</th>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1981</th>\n",
              "      <td>92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1982</th>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1983</th>\n",
              "      <td>82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1984</th>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1985</th>\n",
              "      <td>68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1986</th>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1987</th>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1988</th>\n",
              "      <td>89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1989</th>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1990</th>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1991</th>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1992</th>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1993</th>\n",
              "      <td>89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1994</th>\n",
              "      <td>89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2001</th>\n",
              "      <td>77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002</th>\n",
              "      <td>81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2003</th>\n",
              "      <td>77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2004</th>\n",
              "      <td>58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2005</th>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006</th>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2007</th>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008</th>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2009 rows  1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      category\n",
              "0           19\n",
              "1            4\n",
              "2           40\n",
              "3           95\n",
              "4           51\n",
              "5           40\n",
              "6           67\n",
              "7           97\n",
              "8           72\n",
              "9           89\n",
              "10          63\n",
              "11          86\n",
              "12          89\n",
              "13          63\n",
              "14          15\n",
              "15          19\n",
              "16          10\n",
              "17          10\n",
              "18          81\n",
              "19          97\n",
              "20          85\n",
              "21          76\n",
              "22          74\n",
              "23           4\n",
              "24          76\n",
              "25          14\n",
              "26          85\n",
              "27          43\n",
              "28          19\n",
              "29          57\n",
              "...        ...\n",
              "1979        74\n",
              "1980        43\n",
              "1981        92\n",
              "1982        62\n",
              "1983        82\n",
              "1984        39\n",
              "1985        68\n",
              "1986        31\n",
              "1987        74\n",
              "1988        89\n",
              "1989        25\n",
              "1990        42\n",
              "1991        63\n",
              "1992        30\n",
              "1993        89\n",
              "1994        89\n",
              "1995        30\n",
              "1996        58\n",
              "1997        72\n",
              "1998        81\n",
              "1999        77\n",
              "2000         4\n",
              "2001        77\n",
              "2002        81\n",
              "2003        77\n",
              "2004        58\n",
              "2005        74\n",
              "2006        30\n",
              "2007        72\n",
              "2008        51\n",
              "\n",
              "[2009 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUbsHl8PcURh",
        "colab_type": "code",
        "outputId": "7816d0c2-b099-465b-81c0-fce3fc9059a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "df_prediction.category.value_counts()"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "73     62\n",
              "77     58\n",
              "94     53\n",
              "51     49\n",
              "46     49\n",
              "43     49\n",
              "74     48\n",
              "50     44\n",
              "81     43\n",
              "30     43\n",
              "75     43\n",
              "89     40\n",
              "97     35\n",
              "88     35\n",
              "4      35\n",
              "31     31\n",
              "76     31\n",
              "60     30\n",
              "72     30\n",
              "82     30\n",
              "20     29\n",
              "42     29\n",
              "58     27\n",
              "41     26\n",
              "19     25\n",
              "39     25\n",
              "14     24\n",
              "56     23\n",
              "98     23\n",
              "78     23\n",
              "       ..\n",
              "99     12\n",
              "6      12\n",
              "92     12\n",
              "100    12\n",
              "18     11\n",
              "16     11\n",
              "38     11\n",
              "61     11\n",
              "35     10\n",
              "22     10\n",
              "68     10\n",
              "11      9\n",
              "7       9\n",
              "55      9\n",
              "86      9\n",
              "1       8\n",
              "34      8\n",
              "40      8\n",
              "53      8\n",
              "67      8\n",
              "21      7\n",
              "45      7\n",
              "33      6\n",
              "87      6\n",
              "90      6\n",
              "102     6\n",
              "28      5\n",
              "9       3\n",
              "93      3\n",
              "26      1\n",
              "Name: category, Length: 102, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "pQSmN3o-eQOo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample = pd.read_csv('../data/sample_submission.csv')\n",
        "\n",
        "#sample['label'] = prediction\n",
        "#sample.to_csv('sample_cnn.csv', header=True, index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "jl4cd0XQeQOu",
        "colab_type": "code",
        "outputId": "782ad312-f3fc-4bef-c524-e4421a693250",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_final= sample.iloc[:,[0]]\n",
        "df_final=pd.concat([df_final,df_prediction],axis=1)\n",
        "df_final.head()"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>18540</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18541</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>18542</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>18543</td>\n",
              "      <td>95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>18544</td>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   image_id  category\n",
              "0     18540        19\n",
              "1     18541         4\n",
              "2     18542        40\n",
              "3     18543        95\n",
              "4     18544        51"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "lJxkyr1teQO1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.DataFrame(df_final).to_csv('myprediction_NN.csv',index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "tL5_daaVeQO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('myprediction_NN.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "uFLM3KRheQPG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}